{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# データセットの操作\n",
        "\n",
        "前のラボでは、*データストア*を使用して、クラウドベースのデータ アクセスを一元化しました。  このラボでは、*データセット*を詳しく調べ、さらなる抽象化を行い、実験やトレーニングのために特定のデータを簡単に操作できるようにします。\n",
        "\n",
        "## ワークスペースに接続する\n",
        "\n",
        "まず、Azure ML SDK を使用してワークスペースに接続する必要があります。\n",
        "\n",
        "> **注**: 前回の演習を完了してから Azure サブスクリプションとの認証済みセッションの有効期限が切れている場合は、再認証を求めるメッセージが表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# 保存した構成ファイルからワークスペースを読み込む\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データを準備する\n",
        "\n",
        "前のラボでは、データストアを作成しました。データセットは、通常、データストアのデータに基づいています (必ずしもそうではありません)。\n",
        "\n",
        "前のラボを完了していない場合は、次のコードを実行して、ワークスペースの既定のデータストアに 2 つのローカル CSV ファイルをアップロードします ( 前の演習を完了*した*場合は、同じファイルが上書きされます)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ws.get_default_datastore().upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # 糖尿病 CSV ファイルを /data にアップロードする\n",
        "                       target_path='diabetes-data/', # データストアのフォルダー パスに入れる\n",
        "                       overwrite=True, # 同じ名前の既存のファイルを置き換える\n",
        "                       show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 表形式データセットを作成する\n",
        "\n",
        "データセットは、特定のデータソースをカプセル化するオブジェクトです。データストアにアップロードした糖尿病データからデータセットを作成し、最初の 20 件のレコードを表示してみましょう。この場合、データは CSV ファイル内の構造化された形式であるため、*表形式*のデータセットを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# 既定のデータストアを取得する\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#データストア上のパスから表形式のデータセットを作成する (しばらく時間がかかる場合があります)\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# 最初の 20 行を Pandas データフレームとして表示する\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上のコードでわかるように、表形式のデータセットを Pandas データフレームに変換するのは簡単で、一般的な Python の手法を使用してデータを操作できます。\n",
        "\n",
        "## ファイル データセットを作成する\n",
        "\n",
        "作成したデータセットは、データセット定義に含まれる構造化ファイル内のすべてのデータを含むデータフレームとして読み取ることができる*表形式*のデータセットです。これは表形式のデータに適していますが、機械学習のシナリオによっては、非構造化データの操作が必要となる場合があります。または、単に自分のコード内のファイルからデータの読み取り処理を行うことが必要となる場合もあります。これを実現するには、*ファイル* データセットを使用して、ファイルのデータを読み取るために使用できる仮想マウント ポイント内のファイル パスのリストを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#データストア上のパスからファイル データセットを作成する (しばらく時間がかかる場合があります)\n",
        "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# データセット内のファイルを取得する\n",
        "for file_path in file_data_set.to_path():\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットを登録する\n",
        "\n",
        "これで、糖尿病データを参照するデータセットを作成したので、それらを登録して、ワークスペースで実行されている実験に簡単にアクセスできるようにすることができます。\n",
        "\n",
        "表形式のデータセットを**糖尿病データセット**、ファイル データセットを**糖尿病ファイル**として登録します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 表形式のデータセットを登録する\n",
        "tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                           name='diabetes dataset',\n",
        "                           description='diabetes data',\n",
        "                           tags = {'format':'CSV'},\n",
        "                           create_new_version=True)\n",
        "\n",
        "# ファイル データセットを登録する\n",
        "file_data_set = file_data_set.register(workspace=ws, \n",
        "                           name='diabetes file dataset',\n",
        "                           description='diabetes files',\n",
        "                           tags = {'format':'CSV'},\n",
        "                           create_new_version=True)\n",
        "\n",
        "print('Datasets registered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Azure ML Studio](https://ml.azure.com) で、ワークスペースの**データセット** ページでデータセットを表示および管理できます。ワークスペース オブジェクトからもデータセットのリストを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Datasets:\")\n",
        "for dataset_name in list(ws.datasets.keys()):\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ラボ 2A および 2B を完了すると、ビジュアル デザイナー ツールを使用して作成された変換が、登録されたデータセットに含まれていることがわかります。また、前の演習で *Studio* インターフェイスを使用して作成したデータセットと同じ名前で**糖尿病データセット**を登録する場合は、データセットの新しい*バージョン*を作成していることがわかります。データセットをバージョン管理できるため、以前の定義に依存する既存の実験やパイプラインを壊すことなくデータセットを再定義できます。既定では、名前付きデータセットの最新バージョンが返されますが、次のようにバージョン番号を指定することで、特定のバージョンのデータセットを取得できます。\n",
        "\n",
        "```python\n",
        "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 表形式データセットからモデルをトレーニングする\n",
        "\n",
        "データセットができたので、そこからモデルのトレーニングを開始する準備が整いました。データセットは、スクリプトの実行に使用される Estimator で、*入力*としてスクリプトに渡すことができます。\n",
        "\n",
        "次の 2 つのコード セルを実行して作成します。\n",
        "\n",
        "1.**diabetes_training_from_tab_dataset** という名前のフォルダー\n",
        "2.*入力*として渡される表形式のデータセットを使用して分類モデルをトレーニングするスクリプト。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 実験ファイル用フォルダーを作成する\n",
        "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# ライブラリをインポートする\n",
        "import argparse\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# 正規化ハイパーパラメーターを設定する (スクリプトに引数として渡される)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "args = parser.parse_args()\n",
        "reg = args.reg_rate\n",
        "\n",
        "# 実験実行コンテキストを取得する\n",
        "run = Run.get_context()\n",
        "\n",
        "# 糖尿病データを読み込む (入力データセットとして渡される)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['diabetes'].to_pandas_dataframe()\n",
        "\n",
        "# フィーチャーとラベルを分離する\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# データをトレーニング セットとテスト セットに分割する\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# ロジスティック回帰モデルをトレーニングする\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# 精度を計算する\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC を計算する\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# 出力フォルダーに保存されたファイルは、自動的に実験レコードにアップロードされます\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、スクリプトを実行する Estimator を作成したので、スクリプトによって読み取られるトレーニング データセットの名前付き*入力*を定義できます。\n",
        "\n",
        "> **注**: **Dataset** クラスは **azureml-dataprep** パッケージ (SDK と共にインストールされる) で定義されており、このパッケージには **Pandas** のオプションサポートが含まれています (**to_pandas_dataframe()** メソッドで使用されるため、トレーニング実験を実行する環境にこのパッケージを含める必要があります)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.core import Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# スクリプト パラメーターを設定する\n",
        "script_params = {\n",
        "    '--regularization': 0.1\n",
        "}\n",
        "\n",
        "# トレーニング データセットを取得する\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Estimator を作成する\n",
        "estimator = SKLearn(source_directory=experiment_folder,\n",
        "                    entry_script='diabetes_training.py',\n",
        "                    script_params=script_params,\n",
        "                    compute_target = 'local',\n",
        "                    inputs=[diabetes_ds.as_named_input('diabetes')], # データセット オブジェクトを入力として渡す...\n",
        "                    pip_packages=['azureml-dataprep[pandas]'] # ...したがって、データ準備パッケージが必要です\n",
        "                   )\n",
        "\n",
        "# 実験を作成する\n",
        "experiment_name = 'diabetes-training'\n",
        "experiment = Experiment(workspace = ws, name = experiment_name)\n",
        "\n",
        "# 実験を実行する\n",
        "run = experiment.submit(config=estimator)\n",
        "# 実行中に実行の詳細を表示する\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "初めて実験を実行すると、Python 環境のセットアップに時間がかかる場合があります。以降の実行はより高速になります。\n",
        "\n",
        "実験が完了したら、ウィジェットで、**azureml-logs/70_driver_log.txt** 出力ログと実行によって生成されたメトリックを表示します。\n",
        "\n",
        "すべての実験と同様に、[Azure ML Studio](https://ml.azure.com) で実行された実験の詳細を表示したり、生成されたメトリックとファイルを取得するコードを書き込んだりできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 指標の記録を取得する\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "トレーニングしたモデルは、**outputs** フォルダーに **diabetes_model.pkl** ファイルとして保存されるので、登録することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'SKLearn Estimator (tabular dataset)'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ファイル データセットからモデルをトレーニングする\n",
        "\n",
        "*表形式*データセットでトレーニング データを使用してモデルをトレーニングする方法を見てきましたが、*ファイル* データセットについてはどうでしょうか。\n",
        "\n",
        "ファイル データセットを使用する場合、スクリプトに渡されるデータセット入力は、ファイル パスを含むマウント ポイントを表します。これらのファイルからデータを読み取る方法は、ファイル内のデータの種類と、そのデータを使用して何を行うかによって異なります。糖尿病 CSV ファイルの場合、Python **glob** モジュールを使用して、データセットによって定義された仮想マウント ポイント内のファイルのリストを作成し、それらをすべて単一のデータフレームに連結された Pandas データフレームに読み込むことができます。\n",
        "\n",
        "次の 2 つのコード セルを実行して作成します。\n",
        "\n",
        "1.**diabetes_training_from_file_dataset** という名前のフォルダー\n",
        "2.*入力*として渡されるファイル データセットを使用して分類モデルをトレーニングするスクリプト。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 実験ファイル用フォルダーを作成する\n",
        "experiment_folder = 'diabetes_training_from_file_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# ライブラリをインポートする\n",
        "import argparse\n",
        "from azureml.core import Workspace, Dataset, Experiment, Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import glob\n",
        "\n",
        "# 正規化ハイパーパラメーターを設定する (スクリプトに引数として渡される)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "args = parser.parse_args()\n",
        "reg = args.reg_rate\n",
        "\n",
        "# 実験実行コンテキストを取得する\n",
        "run = Run.get_context()\n",
        "\n",
        "# 糖尿病データセットを読み込む\n",
        "print(\"Loading Data...\")\n",
        "data_path = run.input_datasets['diabetes'] # Estimator 入力からトレーニング データを取得する\n",
        "all_files = glob.glob(data_path + \"/*.csv\")\n",
        "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
        "\n",
        "# フィーチャーとラベルを分離する\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# データをトレーニング セットとテスト セットに分割する\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# ロジスティック回帰モデルをトレーニングする\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# 精度を計算する\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC を計算する\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# 出力フォルダーに保存されたファイルは、自動的に実験レコードにアップロードされます\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に、データセットを Estimator に渡す方法を変更する必要があります。スクリプトがファイルを読み取ることができるマウント ポイントを定義する必要があります。通常、大量のデータの場合、**as_mount** メソッドを使用して、データセット ソースから直接ファイルをストリーミングしますが、ローカル コンピューティングで実行する場合 (この例のように) は、**as_download** オプションを使用して、データセット ファイルをローカル フォルダーにダウンロードする必要があります。\n",
        "\n",
        "また、**Dataset** クラスは **azureml-dataprep** パッケージで定義されているため、実験環境に含める必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.core import Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# スクリプト パラメーターを設定する\n",
        "script_params = {\n",
        "    '--regularization': 0.1\n",
        "}\n",
        "\n",
        "# トレーニング データセットを取得する\n",
        "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
        "\n",
        "# Estimator を作成する\n",
        "estimator = SKLearn(source_directory=experiment_folder,\n",
        "                    entry_script='diabetes_training.py',\n",
        "                    script_params=script_params,\n",
        "                    compute_target = 'local',\n",
        "                    inputs=[diabetes_ds.as_named_input('diabetes').as_download(path_on_compute='diabetes_data')], # データセット オブジェクトを入力として渡す\n",
        "                    pip_packages=['azureml-dataprep[pandas]'] # したがって、データ準備パッケージが必要です\n",
        "                   )\n",
        "\n",
        "# 実験を作成する\n",
        "experiment_name = 'diabetes-training'\n",
        "experiment = Experiment(workspace = ws, name = experiment_name)\n",
        "\n",
        "# 実験を実行する\n",
        "run = experiment.submit(config=estimator)\n",
        "# 実行中に実行の詳細を表示する\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実験が完了したら、ウィジェットで **azureml-logs/70_driver_log.txt** 出力ログを表示し、ファイル データセットが処理され、データ ファイルがダウンロードされたことを確認します。\n",
        "\n",
        "すべての実験と同様に、[Azure ML Studio](https://ml.azure.com) で実行された実験の詳細を表示したり、生成されたメトリックとファイルを取得するコードを書き込んだりできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 指標の記録を取得する\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "もう一度、トレーニングしたモデルを登録してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'SKLearn Estimator (file dataset)'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **詳細情報**: データセットを使用するトレーニングの詳細については、Azure ML ドキュメントの[データセットを使用するトレーニング](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets)を参照してください。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}