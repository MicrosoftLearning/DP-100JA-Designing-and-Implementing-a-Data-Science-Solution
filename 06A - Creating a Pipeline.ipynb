{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインを作成する\n",
    "\n",
    "前のラボでは、Azure Machine Learning SDK を使用して、データへのアクセスからトレーニング実験の実行、機械学習モデルの登録に至るモデル トレーニング プロセス全体を説明しました。これまでは、機械学習ソリューションを対話形式で作成するために必要なさまざまな手順を実行してきました。このラボでは、*パイプライン*を使用してこれらの手順を自動化する方法について説明します。\n",
    "\n",
    "## ワークスペースに接続する\n",
    "\n",
    "まず、Azure ML SDK を使用してワークスペースに接続する必要があります。\n",
    "\n",
    "> **注**: 前回の演習を完了してから Azure サブスクリプションとの認証済みセッションの有効期限が切れている場合は、再認証を求めるメッセージが表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# 保存した構成ファイルからワークスペースを読み込む\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験用データを準備する\n",
    "\n",
    "このラボでは、糖尿病患者の詳細を含むデータセットを使用します。次のセルを実行してこのデータセットを作成します (前のラボで作成した場合は、コードによって既存のバージョンが検索されます)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプライン ステップ用スクリプトを作成する\n",
    "\n",
    "パイプラインは、Python スクリプト、自動 ML トレーニング Estimator のような特殊なステップ、データをある場所から別の場所にコピーするデータ転送ステップなど、1 つ以上の*ステップ*で構成されます。各ステップは、独自のコンピューティング コンテキストで実行できます。\n",
    "\n",
    "この演習では、(モデルをトレーニングするための) Estimator ステップと (トレーニング済みモデルを登録するための) Python スクリプト ステップを含む単純なパイプラインを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# パイプライン ステップ ファイル用フォルダーを作成する\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、モデルをトレーニングする最初のステップのスクリプトを作成できます。スクリプトには、トレーニング済みモデルを保存するフォルダーを参照する **output_folder** という名前のパラメーターが含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# ライブラリをインポートする\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# パラメーターを取得する\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# 実験実行コンテキストを取得する\n",
    "run = Run.get_context()\n",
    "\n",
    "# 糖尿病データを読み込む (入力データセットとして渡される)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "\n",
    "# フィーチャーとラベルを分離する\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# データをトレーニング セットとテスト セットに分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# デシジョン ツリー モデルをトレーニングする\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# AUC を計算する\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# ROC 曲線をプロットする\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# 対角 50% ラインをプロットする\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# モデルによって達成された FPR と TPR をプロットする\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# トレーニング済みモデルを保存する\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パイプラインの 2 番目のステップのスクリプトは、保存された場所からモデルを読み込み、ワークスペースに登録します。これには、モデルが保存されたパスを含む単一の **model_folder** パラメーターが含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# ライブラリをインポートする\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# パラメーターを取得する\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# 実験実行コンテキストを取得する\n",
    "run = Run.get_context()\n",
    "\n",
    "# モデルを読み込む\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプライン ステップ用コンピューティング環境を準備する\n",
    "\n",
    "この演習では、両方のステップで同じコンピューティングを使用しますが、各ステップは独立して実行されることを認識することが重要です。必要に応じて、各ステップに異なるコンピューティング コンテキストを指定できます。\n",
    "\n",
    "最初に、前のラボで作成したコンピューティング ターゲットを取得します (存在しない場合は作成されます)。\n",
    "\n",
    "> **重要**: 実行する前に、*コンピューティング クラスター*を以下のコードでコンピューティング クラスターの名前に変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "# クラスターが存在することを確認する\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS2_V2', \n",
    "                                                           max_nodes=2)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコンピューティングには、必要なパッケージの依存関係がインストールされた Python 環境が必要となるため、実行構成を作成する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# 実験用 Python 環境を作成する\n",
    "diabetes_env = Environment(\"diabetes-experiment-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# パッケージの依存関係のセットを作成する\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib', 'pandas'],\n",
    "                                             pip_packages=['azureml-sdk','pyarrow'])\n",
    "\n",
    "# 環境に依存関係を追加する\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# 環境を登録する (前のラボが完了していない場合)\n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-experiment-env')\n",
    "\n",
    "# パイプライン用の新しい runconfig オブジェクトを作成する\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# 上記で作成したコンピューティングを使用します。 \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# 環境を実行構成に割り当てる\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプラインを作成および実行する\n",
    "\n",
    "これで、パイプラインを作成および実行する準備が整いました。\n",
    "\n",
    "まず、パイプライン用ステップと、パイプライン間で渡す必要があるデータ参照を定義する必要があります。この場合、最初のステップでは、2 番目のステップで読み取ることができるフォルダーにモデルを書き込む必要があります。ステップはリモート コンピューティングで実行されるため (実際には、それぞれ異なるコンピューティングで実行できます)、ワークスペース内のデータストア内の場所に、フォルダー パスをデータ参照として渡す必要があります。**PipelineData** オブジェクトは、パイプライン ステップ間で渡すことができる中間ストレージの場所に使用される特殊な種類のデータ参照であるため、1 つを作成し、最初のステップの出力と 2 番目のステップの入力として使用します。また、コードがデータ参照によって参照されるデータストアの場所にアクセスできるように、スクリプト引数として渡す必要があることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# トレーニング データセットを取得する\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# モデル フォルダー用パイプラインデータ (一時データ参照) を作成する\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_diabetes.py')\n",
    "\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# 手順 2、モデル登録スクリプトを実行する\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_diabetes.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、定義した手順からパイプラインを構築し、実験として実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# パイプラインを構築する\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# 実験を作成してパイプラインを実行する\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のウィジェットは、実行時のパイプラインの詳細を示しています。[Azure Machine Learning Studio](https://ml.azure.com) の**実験**ページでパイプラインの実行を監視することもできます。\n",
    "\n",
    "パイプラインが終了したら、新しいモデルを*トレーニング コンテキスト* タグに登録して、パイプラインでトレーニングされたことを示します。これを確認するには、次のコードを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは、原理を示すために設計された簡単な例です。実際には、より高度なロジックをパイプライン ステップに組み込むことができます。たとえば、一部のテスト データに対してモデルを評価して AUC や精度などのパフォーマンス メトリックを計算し、以前に登録したモデルのバージョンのメトリックと比較して、パフォーマンスが向上した場合のみ新しいモデルを登録します。\n",
    "\n",
    "[Azure DevOps 用 Azure Machine Learning 拡張機能](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml)を使用して、Azure ML パイプラインと Azure DevOps パイプラインを組み合わせて (そう、同じ名前委の場合は混乱*します*)、モデルの再トレーニングを*継続的統合/継続的デプロイ (CI/CD) プロセス*に統合します。たとえば、Azure DevOps *ビルド* パイプラインを使用して、モデルをトレーニングおよび登録する Azure ML パイプラインをトリガーし、モデルが登録されると、モデルを Web サービスとしてデプロイする Azure Devops *リリース* パイプラインとモデルを使用するアプリケーションまたはサービスをトリガーできます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}