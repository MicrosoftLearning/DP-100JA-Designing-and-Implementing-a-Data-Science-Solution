{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパーパラメーターのチューニング\n",
    "\n",
    "*ハイパーパラメーター* (トレーニングに影響を与えるが、トレーニングデータ自体からは決定できないパラメーター値) を必要とする機械学習アルゴリズムは多数あります。たとえば、ロジスティック回帰モデルをトレーニングする場合、*正規化率* ハイパーパラメーターを使用してモデルのバイアスに対抗できます。畳み込みニューラル ネットワークをトレーニングする場合、*学習率* や *バッチ サイズ* などのハイパーパラメーターを使用して、重みの調整方法とミニバッチで処理されるデータ項目の数をそれぞれ制御できます。ハイパーパラメーター値の選択は、トレーニング済みモデルのパフォーマンスやトレーニングにかかる時間に大きく影響する可能性があります。多くの場合、最適なソリューションを見つけるには複数の組み合わせを試す必要があります。\n",
    "\n",
    "この場合、単一のハイパーパラメーターを使用したロジスティック回帰モデルの簡単な例を使用しますが、Azure Machine Learning でトレーニングできるあらゆる種類のモデルに原則が適用されます。\n",
    "\n",
    "## ワークスペースに接続する\n",
    "\n",
    "まず、Azure ML SDK を使用してワークスペースに接続する必要があります。\n",
    "\n",
    "> **注**: 前回の演習を完了してから Azure サブスクリプションとの認証済みセッションの有効期限が切れている場合は、再認証を求めるメッセージが表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# 保存した構成ファイルからワークスペースを読み込む\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験用データを準備する\n",
    "\n",
    "このラボでは、糖尿病患者の詳細を含むデータセットを使用します。次のセルを実行してこのデータセットを作成します (前のラボで作成した場合、コードは新しいバージョンを作成します)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トレーニング スクリプトを準備する\n",
    "\n",
    "まず、ロジスティック回帰モデルのトレーニングに使用するトレーニング スクリプト用フォルダーを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "experiment_folder = 'diabetes_training-hyperdrive'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print('Folder ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、モデルをトレーニングする Python スクリプトを作成します。これには、次の項目が含まれている必要があります。\n",
    "\n",
    "- 最適化する各ハイパーパラメーターのパラメーター (この場合は、正規化ハイパーパラメーターのみ)\n",
    "- 最適化するパフォーマンス メトリックを記録するコード (この場合、AUC と精度の両方を記録するため、どちらかのモデルを最適化することを選択できます)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# ライブラリをインポートする\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 正規化パラメーターを設定する\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# 実験実行コンテキストを取得する\n",
    "run = Run.get_context()\n",
    "\n",
    "# 糖尿病データセットを読み込む\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
    "\n",
    "# 特徴とラベルを分離する\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# データをトレーニング セットとテスト セットに分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# ロジスティック回帰モデルのトレーニング\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# 正確さを計算する\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# AUC を計算する\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# 出力フォルダーに保存されたファイルは、自動的に実験レコードにアップロードされます\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンピューティング先を準備する\n",
    "\n",
    "クラウド コンピューティングの利点の 1 つは、オンデマンドでスケーリングできることです。これにより、それぞれが異なるハイパーパラメーター値を持つ実験の複数の実行を並行して処理するのに十分なコンピューティング リソースをプロビジョニングできます。\n",
    "\n",
    "以前のラボで作成した Azure Machine Learning コンピューティング クラスターを使用します (これがない場合は作成されます)。\n",
    "\n",
    "> **重要**: 実行する前に、*コンピューティング クラスター* を以下のコードでコンピューティング クラスターの名前に変更してください。クラスター名は、長さが 2 〜 16 文字のグローバルに一意の名前である必要があります。英字、数字、- の文字が有効です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *ハイパードライブ* 実験を実行する\n",
    "\n",
    "Azure Machine Learning には、*ハイパードライブ* 実験を通じたハイパーパラメーター チューニング機能が含まれています。これらの実験は、それぞれが異なるハイパーパラメーターの組み合わせで、複数の子の実行を起動します。最適なモデルを作成する実行 (最適化するターゲットのパフォーマンス メトリックの記録によって決定される) を特定し、登録およびデプロイに選択されたトレーニング済みモデルを特定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# 実験用 Python 環境を作成する\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# 必要なパッケージがインストールされていることを確認する (scikit-learn、Azure ML defaults、Azure ML dataprep が必要)\n",
    "packages = CondaDependencies.create(pip_packages=['scikit-learn','azureml-defaults','azureml-dataprep[pandas]'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# トレーニング データセットを取得する\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# スクリプト構成を作成する\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                              script='diabetes_training.py',\n",
    "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                              environment=sklearn_env,\n",
    "                              compute_target = training_cluster)\n",
    "\n",
    "# パラメーター値の範囲をサンプリングする\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # There's only one parameter, so grid sampling will try each value - with multiple parameters it would try every combination\n",
    "        '--regularization': choice(0.001, 0.005, 0.01, 0.05, 0.1, 1.0)\n",
    "    }\n",
    ")\n",
    "\n",
    "# ハイパードライブ設定を構成する\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
    "                          hyperparameter_sampling=params, \n",
    "                          policy=None, \n",
    "                          primary_metric_name='AUC', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=6,\n",
    "                          max_concurrent_runs=4)\n",
    "\n",
    "# 実験を実行する\n",
    "experiment = Experiment(workspace = ws, name = 'diabates_training_hyperdrive')\n",
    "run = experiment.submit(config=hyperdrive)\n",
    "\n",
    "# 実験の実行時に Notebook の状態を表示する\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のウィジェットで実験の実行状態を表示できます。また、[Azure Machine Learning Studio](https://ml.azure.com) で、メインのハイパードライブ実験の実行とその子の実行を表示することもできます。\n",
    "\n",
    "> **注**: ウィジェットは更新されない場合があります。実行が完了すると、ウィジェットの下に概要情報が表示されます。\n",
    "\n",
    "## パフォーマンスの最も高い実行を決定する\n",
    "\n",
    "すべての実行が終了したら、指定したパフォーマンス メトリック (この場合は最高の AUC を持つもの) に基づいて最適な実行を見つけることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child_run in run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)\n",
    "\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details() ['runDefinition']['arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print(' -AUC:', best_run_metrics['AUC'])\n",
    "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
    "print(' -Regularization Rate:',parameter_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適な実行が見つかったので、トレーニングしたモデルを登録できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# モデルを登録する\n",
    "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                        tags={'Training context':'Hyperdrive'},\n",
    "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\n",
    "\n",
    "# 登録済みモデルを一覧表示する\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **詳細情報**: ハイパードライブの詳細については、[Azure ML のドキュメント](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)を参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}